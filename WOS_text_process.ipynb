{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b5c5a8-d108-4e52-8039-1f57a748879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3431d4-d550-4600-b88b-1f1799982c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files for Social Networks...\n",
      "Data for Social Networks saved to Social_Networks_data.csv\n",
      "Processing files for Network Science...\n",
      "Data for Network Science saved to Network_Science_data.csv\n",
      "Processing files for Journal of Complex Networks...\n",
      "Data for Journal of Complex Networks saved to Journal_of_Complex_Networks_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Define paths for the three journals\n",
    "paths = {\n",
    "    \"Social Networks\": \"Social Networks/WOS data/\",\n",
    "    \"Network Science\": \"Network Science/WOS data/\",\n",
    "    \"Journal of Complex Networks\": \"Journal of Complex Networks/WOS data/\"\n",
    "}\n",
    "\n",
    "# Function to process WOS files in a given directory\n",
    "def process_wos_files(input_directory):\n",
    "    papers = []  # List to store processed records\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith(\".txt\"):  # Only process .txt files\n",
    "            filepath = os.path.join(input_directory, filename)\n",
    "            try:\n",
    "                with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                    data = file.read()\n",
    "                    # Split the content into individual records using the delimiter 'ER'\n",
    "                    records = data.split(\"\\nER\\n\")\n",
    "                    for record in records:\n",
    "                        if not record.strip():  # Skip empty records\n",
    "                            continue\n",
    "                        paper = {}\n",
    "                        # Extract fields safely\n",
    "                        paper['Document Type'] = re.search(r\"PT (.+)\", record).group(1) if re.search(r\"PT (.+)\", record) else None\n",
    "                        paper['Authors'] = re.findall(r\"AU (.+)\", record)  # List of authors\n",
    "                        paper['Title'] = re.search(r\"TI (.+)\", record).group(1) if re.search(r\"TI (.+)\", record) else None\n",
    "                        paper['Journal'] = re.search(r\"SO (.+)\", record).group(1) if re.search(r\"SO (.+)\", record) else None\n",
    "                        paper['Year'] = re.search(r\"PY (.+)\", record).group(1) if re.search(r\"PY (.+)\", record) else None\n",
    "                        \n",
    "                        # Safely extract citation count\n",
    "                        tc_match = re.search(r\"TC (\\d+)\", record)\n",
    "                        paper['Citations'] = int(tc_match.group(1)) if tc_match else 0\n",
    "\n",
    "                        # Extract keywords (combine 'DE' and 'ID' fields)\n",
    "                        paper['Keywords'] = re.findall(r\"DE (.+)\", record) + re.findall(r\"ID (.+)\", record)\n",
    "\n",
    "                        # Extract DOI\n",
    "                        paper['DOI'] = re.search(r\"DI (.+)\", record).group(1) if re.search(r\"DI (.+)\", record) else None\n",
    "\n",
    "                        # Extract affiliations\n",
    "                        paper['Affiliations'] = re.findall(r\"RP (.+)\", record)\n",
    "\n",
    "                        # Extract references (list of cited references)\n",
    "                        paper['References'] = re.findall(r\"CR (.+)\", record)\n",
    "\n",
    "                        # Add the processed paper to the list\n",
    "                        papers.append(paper)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filepath}: {e}\")\n",
    "    return papers\n",
    "\n",
    "# Process each journal and save results\n",
    "for journal, path in paths.items():\n",
    "    print(f\"Processing files for {journal}...\")\n",
    "    try:\n",
    "        journal_data = process_wos_files(path)  # Process WOS files for the journal\n",
    "        df = pd.DataFrame(journal_data)  # Convert the list of papers into a DataFrame\n",
    "\n",
    "        # Save the processed data to a CSV file\n",
    "        output_file = f\"{journal.replace(' ', '_')}_data.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Data for {journal} saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {journal}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650bd742-3a70-4d0c-a9e6-e2b28555e035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
